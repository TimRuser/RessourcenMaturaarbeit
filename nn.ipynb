{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuronales Netz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "numOfFeaturesAtStart = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "numOfFeaturesAddedToSections = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplifiedModel(nn.Module):\n",
    "    def __init__(self, n_layers = 3, hiddenLayerNumNodes = 64):\n",
    "        super(SimplifiedModel, self).__init__()\n",
    "        \n",
    "        self.numLayers = n_layers\n",
    "\n",
    "        self.fcIn = nn.Linear(numOfFeaturesAtStart + 12 * (19 + numOfFeaturesAddedToSections), 64)\n",
    "        self.fcStart = nn.Linear(64, hiddenLayerNumNodes)\n",
    "        self.fcInner = nn.Linear(hiddenLayerNumNodes,hiddenLayerNumNodes)\n",
    "        self.fcEnd = nn.Linear(hiddenLayerNumNodes, 16)\n",
    "        self.fc_out = nn.Linear(16, 1)     \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fcIn(x))\n",
    "        x = self.relu(self.fcStart(x))\n",
    "\n",
    "        for i in range(self.numLayers):\n",
    "            x = self.relu(self.fcInner(x))\n",
    "\n",
    "        x = self.relu(self.fcEnd(x))\n",
    "        x = self.sigmoid(self.fc_out(x))        \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                [-1, 1, 64]          15,744\n",
      "              ReLU-2                [-1, 1, 64]               0\n",
      "            Linear-3                [-1, 1, 64]           4,160\n",
      "              ReLU-4                [-1, 1, 64]               0\n",
      "            Linear-5                [-1, 1, 64]           4,160\n",
      "              ReLU-6                [-1, 1, 64]               0\n",
      "            Linear-7                [-1, 1, 64]           4,160\n",
      "              ReLU-8                [-1, 1, 64]               0\n",
      "            Linear-9                [-1, 1, 64]           4,160\n",
      "             ReLU-10                [-1, 1, 64]               0\n",
      "          Dropout-11                [-1, 1, 64]               0\n",
      "           Linear-12                [-1, 1, 16]           1,040\n",
      "             ReLU-13                [-1, 1, 16]               0\n",
      "           Linear-14                 [-1, 1, 1]              17\n",
      "          Sigmoid-15                 [-1, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 33,441\n",
      "Trainable params: 33,441\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.13\n",
      "Estimated Total Size (MB): 0.13\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summaryModel = SimplifiedModel().to(torch.device('cuda'))\n",
    "summary(summaryModel, input_size=(1, numOfFeaturesAtStart + 12 * (19 + numOfFeaturesAddedToSections)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_json('datasets/data.json', orient='records')\n",
    "df_control = pd.read_json('datasets/control.json', orient='records')\n",
    "df = pd.concat([df_data, df_control], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700\n"
     ]
    }
   ],
   "source": [
    "print(len(df_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1726\n"
     ]
    }
   ],
   "source": [
    "print(len(df_control))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['sections'].values\n",
    "numSections = df['numSections'].values\n",
    "fullEntropy = df['fullEntropy'].values\n",
    "minEntropy = df['minEntropy'].values\n",
    "maxEntropy = df['maxEntropy'].values\n",
    "X_entropyList = df['entropyList'].values\n",
    "y = df['label'].values\n",
    "y = [label for label in y] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.tolist()\n",
    "numSections = numSections.tolist()\n",
    "fullEntropy = fullEntropy.tolist()\n",
    "minEntropy = minEntropy.tolist()\n",
    "maxEntropy = maxEntropy.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "averageChunkEntropy = [0] * len(X_entropyList)\n",
    "for i in range(len(X_entropyList)):\n",
    "    averageChunkEntropy[i] = sum(X_entropyList[i]) / len(X_entropyList[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunkEntropyVariance = [0] * len(X_entropyList)\n",
    "for i in range(len(X_entropyList)):\n",
    "    chunkEntropyVariance[i] = np.var(X_entropyList[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileLength = [0] * len(X_entropyList)\n",
    "for i in range(len(X_entropyList)):\n",
    "    fileLength[i] = 2048 * len(X_entropyList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "numSectionsAboveCertainEntropy = [0] * len(X)\n",
    "for i in range(len(X)):\n",
    "    numSectionsAboveCertainEntropy[i] = sum([1 for item in X[i] if item[-1] > 7.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X)):\n",
    "        for entry in X[i]:\n",
    "                entry[-2] /= 1e+8\n",
    "                entry[-1] /= 8\n",
    "                entry.append(entry[-1] / (fullEntropy[i] + 1e-8 / 8))\n",
    "        # X[i].insert(0,numSections[i] / 12)\n",
    "        X[i].insert(0,chunkEntropyVariance[i] / 8)\n",
    "        X[i].insert(0,averageChunkEntropy[i] / 8)\n",
    "        X[i].insert(0,fullEntropy[i] / 8)\n",
    "        X[i].insert(0,minEntropy[i] / 8)\n",
    "        X[i].insert(0,maxEntropy[i] / 8)\n",
    "        # X[i].insert(0,numSectionsAboveCertainEntropy[i] / 12)\n",
    "        # X[i].insert(0, fileLength[i] / 1e+8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "X2 = X\n",
    "entropy_range = 0.5 / 8\n",
    "byte_range = 250 / 1e+8\n",
    "for i in range(len(X2)):\n",
    "    for e, entry in enumerate(X2[i]):\n",
    "        if e <= numOfFeaturesAtStart - 1:\n",
    "            continue\n",
    "        entry[-3] += random.uniform(-byte_range, byte_range)\n",
    "        entry[-2] += random.uniform(-entropy_range, entropy_range)\n",
    "        entry[-1] += random.uniform(-entropy_range, entropy_range)\n",
    "    for e in range(numOfFeaturesAtStart):\n",
    "        if e == -1:\n",
    "            continue\n",
    "        if e == -1:\n",
    "            X2[i][e] += random.uniform(-byte_range, byte_range)\n",
    "            continue\n",
    "        X2[i][e] += random.uniform(-entropy_range, entropy_range)\n",
    "    # X2[i][4] += random.uniform(-entropy_range, entropy_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "X += X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X)):\n",
    "    X[i] = X[i][0:numOfFeaturesAtStart] + [item for sublist in X[i][numOfFeaturesAtStart:] for item in sublist] ## X[i][0:5] + "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateNewSplit():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "withOptuna = False\n",
    "testMore = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recall(y_true, y_pred):\n",
    "    true_positives = (y_true * y_pred).sum()\n",
    "    false_negatives = (y_true * (1 - y_pred)).sum()\n",
    "    \n",
    "    recall = true_positives / (true_positives + false_negatives + 1e-8)\n",
    "    return recall.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(losses, accuracies, val_losses, val_accuracies, recalls, val_recalls):\n",
    "    epochs = range(1, len(losses) + 1)\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(epochs, losses, label='Loss', color='slategrey')\n",
    "    plt.plot(epochs, val_losses, label='Validation Loss', color='cornflowerblue')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(epochs, accuracies, label='Accuracy', color='seagreen')\n",
    "    plt.plot(epochs, val_accuracies, label='Validation Accuracy', color='lime')\n",
    "    plt.title('Training Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(epochs, recalls, label='Recall', color='seagreen')\n",
    "    plt.plot(epochs, val_recalls, label='Validation Recall', color='lime')\n",
    "    plt.title('Training Recall')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, scheduler, device, num_epochs=10, trial=None):\n",
    "    \n",
    "    all_losses = []\n",
    "    all_accuracies = []\n",
    "    all_val_losses = []\n",
    "    all_val_accuracies = []\n",
    "    all_recalls = []\n",
    "    all_val_recalls = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        fold_results = []\n",
    "\n",
    "        for fold, (train_index, val_index) in enumerate(kf.split(X_train_tensor)):\n",
    "\n",
    "            X_train, X_val = X_train_tensor[train_index], X_train_tensor[val_index]\n",
    "            y_train, y_val = y_train_tensor[train_index], y_train_tensor[val_index]\n",
    "\n",
    "            train_dataset = TensorDataset(X_train, y_train)\n",
    "            val_dataset = TensorDataset(X_val, y_val)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "            model.train()\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            correct_predictions = 0\n",
    "            total_samples = 0\n",
    "            fold_recall = 0.0\n",
    "\n",
    "            for inputs, targets in train_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                loss = criterion(outputs.squeeze(), targets.float())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                predicted = (outputs.squeeze() > 0.5).float()\n",
    "                correct_predictions += (predicted == targets).sum().item()\n",
    "                total_samples += targets.size(0)\n",
    "\n",
    "                fold_recall += calculate_recall(targets, predicted)\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            val_loss = 0\n",
    "            correct_val_predictions = 0\n",
    "            fold_val_recall = 0\n",
    "            total_val_samples = 0\n",
    "            with torch.no_grad():\n",
    "                for inputs, targets in val_loader:\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    outputs = model(inputs)\n",
    "\n",
    "                    loss = criterion(outputs.squeeze(), targets.float())\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "                    predicted = (outputs.squeeze() > 0.5).float()\n",
    "                    correct_val_predictions += (predicted == targets).sum().item()\n",
    "                    total_val_samples += targets.size(0)\n",
    "\n",
    "                    fold_val_recall += calculate_recall(targets, predicted)\n",
    "\n",
    "\n",
    "            fold_loss = running_loss / len(train_loader)\n",
    "            fold_accuracy = correct_predictions / total_samples\n",
    "            fold_recall /= len(train_loader)\n",
    "            fold_val_loss = val_loss / len(val_loader)\n",
    "            fold_val_accuracy = correct_val_predictions / total_val_samples\n",
    "            fold_val_recall /= len(val_loader)\n",
    "\n",
    "            fold_combined_accuracy = (correct_predictions + correct_val_predictions) / (total_samples + total_val_samples)\n",
    "\n",
    "            fold_results.append((fold_loss, fold_accuracy, fold_recall, fold_val_loss, fold_val_accuracy, fold_val_recall, fold_combined_accuracy))\n",
    "\n",
    "        all_losses.append(np.mean([result[0] for result in fold_results]))\n",
    "        all_accuracies.append(np.mean([result[1] for result in fold_results]))\n",
    "        all_recalls.append(np.mean([result[2] for result in fold_results]))\n",
    "        all_val_losses.append(np.mean([result[3] for result in fold_results]))\n",
    "        all_val_accuracies.append(np.mean([result[4] for result in fold_results]))\n",
    "        all_val_recalls.append(np.mean([result[5] for result in fold_results]))\n",
    "\n",
    "        if withOptuna and trial:\n",
    "            trial.report(np.mean([result[6] for result in fold_results]), epoch)\n",
    "            \n",
    "            if trial.should_prune():\n",
    "                # raise optuna.TrialPruned()\n",
    "                pass\n",
    "\n",
    "        if not withOptuna:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {fold_loss:.4f}, Recall: {fold_recall*100:.2f}%, Accuracy: {fold_accuracy*100:.2f}%, Val Loss: {fold_val_loss:.4f}, Val Recall: {fold_val_recall*100:.2f}%, Val Accuracy: {fold_val_accuracy*100:.2f}%, Recall Spread: {(fold_recall-fold_val_recall) * 100:.2f}', end='\\r')\n",
    "\n",
    "    if not withOptuna and not testMore:\n",
    "        plot_loss_accuracy(all_losses, all_accuracies, all_val_losses, all_val_accuracies, all_recalls, all_val_recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not withOptuna and not testMore:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = SimplifiedModel(2, 64).to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.002, weight_decay=5e-6)\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "    train(model, criterion, optimizer, scheduler, device, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, criterion, device, printResult=True):\n",
    "    model.eval() \n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    recall = 0.0\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        for inputs, targets in test_loader:\n",
    "\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs.squeeze(), targets.float())\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            predicted = (outputs.squeeze() > 0.5).float() \n",
    "            correct_predictions += (predicted == targets).sum().item()\n",
    "            total_samples += targets.size(0)\n",
    "\n",
    "            recall += calculate_recall(targets, predicted)\n",
    "\n",
    "    average_loss = total_loss / len(test_loader)\n",
    "    accuracy = (correct_predictions / total_samples)\n",
    "    recall /= len(test_loader)\n",
    "\n",
    "    if printResult:\n",
    "        print(f'Test Loss: {average_loss:.4f}, Test Recall: {recall*100:.2f}%, Test Accuracy: {accuracy*100:.2f}%', end='\\r\\n')\n",
    "\n",
    "    return average_loss, accuracy, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not withOptuna and not testMore:\n",
    "    test(model, test_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' if testMore and not withOptuna:\\n\\n    resultsAccuracy = []\\n    resultsRecall = []\\n\\n    for i in range(10):\\n\\n        print(\"Trial \" + str(i + 1), end=\\'\\n\\')\\n\\n        generateNewSplit()\\n\\n        device = torch.device(\\'cuda\\' if torch.cuda.is_available() else \\'cpu\\')\\n        model = SimplifiedModel(4, 128).to(device)\\n        criterion = nn.BCELoss()\\n        optimizer = optim.Adam(model.parameters(), lr=0.002, weight_decay=3.7e-6)\\n        scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.978)\\n        train(model, criterion, optimizer, scheduler, device, 50)\\n\\n        results = test(model, test_loader, criterion, device)\\n        resultsAccuracy.append(results[1])\\n        resultsRecall.append(results[2])\\n\\n    resultsDataFrame = pd.DataFrame({\\'Accuracy\\': resultsAccuracy, \\'Recall\\': resultsRecall})\\n    resultsDataFrame.to_json(\"./result.json\")\\n\\n    print(\"Accuracy:\", f\"{sum(resultsAccuracy) / 10 * 100:.2f}%\", \"Recall:\", f\"{sum(resultsRecall) / 10 * 100:.2f}%\") '"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" if testMore and not withOptuna:\n",
    "\n",
    "    resultsAccuracy = []\n",
    "    resultsRecall = []\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        print(\"Trial \" + str(i + 1), end='\\n')\n",
    "\n",
    "        generateNewSplit()\n",
    "\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model = SimplifiedModel(4, 128).to(device)\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.002, weight_decay=3.7e-6)\n",
    "        scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.978)\n",
    "        train(model, criterion, optimizer, scheduler, device, 50)\n",
    "\n",
    "        results = test(model, test_loader, criterion, device)\n",
    "        resultsAccuracy.append(results[1])\n",
    "        resultsRecall.append(results[2])\n",
    "\n",
    "    resultsDataFrame = pd.DataFrame({'Accuracy': resultsAccuracy, 'Recall': resultsRecall})\n",
    "    resultsDataFrame.to_json(\"./result.json\")\n",
    "\n",
    "    print(\"Accuracy:\", f\"{sum(resultsAccuracy) / 10 * 100:.2f}%\", \"Recall:\", f\"{sum(resultsRecall) / 10 * 100:.2f}%\") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1\n",
      "Test Loss: 0.5491, Test Recall: 98.01%, Test Accuracy: 97.96%0%, Val Loss: 0.0001, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: 0.00\n",
      "Trial 2\n",
      "Test Loss: 0.3147, Test Recall: 98.42%, Test Accuracy: 98.10%0%, Val Loss: 0.0001, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: 0.00\n",
      "Trial 3\n",
      "Test Loss: 0.4078, Test Recall: 98.64%, Test Accuracy: 98.69%, Val Loss: 0.0002, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: -0.05\n",
      "Trial 4\n",
      "Test Loss: 0.2800, Test Recall: 97.65%, Test Accuracy: 97.88%, Val Loss: 0.0019, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: -0.16\n",
      "Trial 5\n",
      "Test Loss: 0.2808, Test Recall: 98.37%, Test Accuracy: 98.54%0%, Val Loss: 0.0004, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: 0.00\n",
      "Trial 6\n",
      "Test Loss: 0.3791, Test Recall: 97.63%, Test Accuracy: 98.25%, Val Loss: 0.0033, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: -0.38\n",
      "Trial 7\n",
      "Test Loss: 0.4650, Test Recall: 97.28%, Test Accuracy: 96.64%, Val Loss: 0.1114, Val Recall: 99.28%, Val Accuracy: 99.09%, Recall Spread: 0.0518\n",
      "Trial 8\n",
      "Test Loss: 0.3981, Test Recall: 98.47%, Test Accuracy: 98.40%0%, Val Loss: 0.0001, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: 0.00\n",
      "Trial 9\n",
      "Test Loss: 0.0857, Test Recall: 99.75%, Test Accuracy: 99.12%0%, Val Loss: 0.0003, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: 0.00\n",
      "Trial 10\n",
      "Test Loss: 0.2895, Test Recall: 97.79%, Test Accuracy: 98.25%0%, Val Loss: 0.0005, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: 0.00\n",
      "Trial 11\n",
      "Test Loss: 0.2407, Test Recall: 97.94%, Test Accuracy: 98.18%, Val Loss: 0.0006, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: -0.06\n",
      "Trial 12\n",
      "Test Loss: 0.4282, Test Recall: 98.77%, Test Accuracy: 98.25%0%, Val Loss: 0.0002, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: 0.00\n",
      "Trial 13\n",
      "Test Loss: 0.4542, Test Recall: 98.11%, Test Accuracy: 98.40%0%, Val Loss: 0.0001, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: 0.00\n",
      "Trial 14\n",
      "Test Loss: 0.3226, Test Recall: 98.32%, Test Accuracy: 97.88%, Val Loss: 0.0002, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: -0.05\n",
      "Trial 15\n",
      "Test Loss: 0.1809, Test Recall: 97.77%, Test Accuracy: 97.96%0%, Val Loss: 0.0001, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: 0.00\n",
      "Trial 16\n",
      "Test Loss: 0.3012, Test Recall: 98.22%, Test Accuracy: 97.81%%, Val Loss: 0.0012, Val Recall: 100.00%, Val Accuracy: 99.91%, Recall Spread: 0.005\n",
      "Trial 17\n",
      "Test Loss: 0.4534, Test Recall: 98.33%, Test Accuracy: 98.25%0%, Val Loss: 0.0001, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: 0.00\n",
      "Trial 18\n",
      "Test Loss: 0.4125, Test Recall: 97.76%, Test Accuracy: 97.96%, Val Loss: 0.0014, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: -0.13\n",
      "Trial 19\n",
      "Test Loss: 0.4100, Test Recall: 99.14%, Test Accuracy: 98.54%%, Val Loss: 0.0009, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: 0.000\n",
      "Trial 20\n",
      "Test Loss: 0.5575, Test Recall: 98.11%, Test Accuracy: 97.96%, Val Loss: 0.0009, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: -0.05\n",
      "Trial 21\n",
      "Test Loss: 0.4134, Test Recall: 98.61%, Test Accuracy: 98.47%, Val Loss: 0.0883, Val Recall: 100.00%, Val Accuracy: 99.91%, Recall Spread: -0.04\n",
      "Trial 22\n",
      "Test Loss: 0.3717, Test Recall: 98.87%, Test Accuracy: 98.32%0%, Val Loss: 0.0031, Val Recall: 100.00%, Val Accuracy: 99.82%, Recall Spread: 0.00\n",
      "Trial 23\n",
      "Test Loss: 0.2856, Test Recall: 98.68%, Test Accuracy: 98.54%0%, Val Loss: 0.0001, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: 0.00\n",
      "Trial 24\n",
      "Test Loss: 0.4410, Test Recall: 97.72%, Test Accuracy: 97.81%, Val Loss: 0.0037, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: -0.39\n",
      "Trial 25\n",
      "Test Loss: 0.4019, Test Recall: 98.72%, Test Accuracy: 98.40%0%, Val Loss: 0.0002, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: 0.00\n",
      "Trial 26\n",
      "Test Loss: 0.4682, Test Recall: 98.33%, Test Accuracy: 98.25%0%, Val Loss: 0.0001, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: 0.00\n",
      "Trial 27\n",
      "Test Loss: 0.2836, Test Recall: 98.25%, Test Accuracy: 98.25%0%, Val Loss: 0.0003, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: 0.00\n",
      "Trial 28\n",
      "Test Loss: 0.2742, Test Recall: 98.22%, Test Accuracy: 98.54%0%, Val Loss: 0.0004, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: 0.00\n",
      "Trial 29\n",
      "Test Loss: 0.3467, Test Recall: 99.48%, Test Accuracy: 98.61%0%, Val Loss: 0.0004, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: 0.00\n",
      "Trial 30\n",
      "Test Loss: 0.0714, Test Recall: 98.89%, Test Accuracy: 98.69%0%, Val Loss: 0.0003, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: 0.00\n",
      "Trial 31\n",
      "Test Loss: 0.5453, Test Recall: 97.95%, Test Accuracy: 98.10%0%, Val Loss: 0.0001, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: 0.00\n",
      "Trial 32\n",
      "Test Loss: 0.3863, Test Recall: 98.64%, Test Accuracy: 98.69%0%, Val Loss: 0.0001, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: 0.00\n",
      "Trial 33\n",
      "Test Loss: 0.2516, Test Recall: 98.77%, Test Accuracy: 98.40%, Val Loss: 0.0022, Val Recall: 100.00%, Val Accuracy: 99.91%, Recall Spread: -0.09\n",
      "Trial 34\n",
      "Test Loss: 0.4051, Test Recall: 97.82%, Test Accuracy: 98.10%0%, Val Loss: 0.0001, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: 0.00\n",
      "Trial 35\n",
      "Test Loss: 0.0736, Test Recall: 98.40%, Test Accuracy: 98.54%, Val Loss: 0.0022, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: -0.090\n",
      "Trial 36\n",
      "Test Loss: 0.3969, Test Recall: 98.58%, Test Accuracy: 98.69%0%, Val Loss: 0.0001, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: 0.00\n",
      "Trial 37\n",
      "Test Loss: 0.3284, Test Recall: 98.35%, Test Accuracy: 98.32%%, Val Loss: 0.0025, Val Recall: 100.00%, Val Accuracy: 99.91%, Recall Spread: 0.00\n",
      "Trial 38\n",
      "Test Loss: 0.3884, Test Recall: 97.81%, Test Accuracy: 97.96%0%, Val Loss: 0.0001, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: 0.00\n",
      "Trial 39\n",
      "Test Loss: 0.3425, Test Recall: 99.15%, Test Accuracy: 98.98%0%, Val Loss: 0.0001, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: 0.00\n",
      "Trial 40\n",
      "Test Loss: 0.2796, Test Recall: 98.03%, Test Accuracy: 97.96%%, Val Loss: 0.0005, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: 0.00\n",
      "Trial 41\n",
      "Test Loss: 0.4492, Test Recall: 97.85%, Test Accuracy: 97.96%0%, Val Loss: 0.0000, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: 0.00\n",
      "Trial 42\n",
      "Test Loss: 0.2625, Test Recall: 97.93%, Test Accuracy: 98.03%, Val Loss: 0.0014, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: -0.06\n",
      "Trial 43\n",
      "Test Loss: 0.5199, Test Recall: 98.60%, Test Accuracy: 98.25%0%, Val Loss: 0.0001, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: 0.00\n",
      "Trial 44\n",
      "Test Loss: 0.4365, Test Recall: 97.57%, Test Accuracy: 98.25%0%, Val Loss: 0.0002, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: 0.00\n",
      "Trial 45\n",
      "Test Loss: 0.4380, Test Recall: 99.27%, Test Accuracy: 98.54%%, Val Loss: 0.0871, Val Recall: 100.00%, Val Accuracy: 99.91%, Recall Spread: 0.00\n",
      "Trial 46\n",
      "Test Loss: 0.3982, Test Recall: 98.28%, Test Accuracy: 98.25%%, Val Loss: 0.0001, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: 0.00\n",
      "Trial 47\n",
      "Test Loss: 0.3863, Test Recall: 98.52%, Test Accuracy: 98.47%, Val Loss: 0.0008, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: -0.05\n",
      "Trial 48\n",
      "Test Loss: 0.4360, Test Recall: 98.60%, Test Accuracy: 98.54%0%, Val Loss: 0.0001, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: 0.00\n",
      "Trial 49\n",
      "Test Loss: 0.3747, Test Recall: 98.32%, Test Accuracy: 98.10%0%, Val Loss: 0.0005, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: 0.00\n",
      "Trial 50\n",
      "Test Loss: 0.3794, Test Recall: 99.19%, Test Accuracy: 98.61%0%, Val Loss: 0.0002, Val Recall: 100.00%, Val Accuracy: 100.00%, Recall Spread: 0.00\n",
      "Accuracy: 491.36% Recall: 491.79%\n"
     ]
    }
   ],
   "source": [
    "if testMore and not withOptuna:\n",
    "\n",
    "    resultsAccuracy = []\n",
    "    resultsRecall = []\n",
    "\n",
    "    for i in range(50):\n",
    "\n",
    "        print(\"Trial \" + str(i + 1), end='\\n')\n",
    "\n",
    "        generateNewSplit()\n",
    "\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model = SimplifiedModel(3, 64).to(device)\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.00225, weight_decay=3.22e-5)\n",
    "        scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9915)\n",
    "        train(model, criterion, optimizer, scheduler, device, 50)\n",
    "\n",
    "        results = test(model, test_loader, criterion, device)\n",
    "        resultsAccuracy.append(results[1])\n",
    "        resultsRecall.append(results[2])\n",
    "\n",
    "    resultsDataFrame = pd.DataFrame({'Accuracy': resultsAccuracy, 'Recall': resultsRecall})\n",
    "    resultsDataFrame.to_json(\"./result.json\")\n",
    "\n",
    "    print(\"Accuracy:\", f\"{sum(resultsAccuracy) / 10 * 100:.2f}%\", \"Recall:\", f\"{sum(resultsRecall) / 10 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import optunahub\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    generateNewSplit()\n",
    "    \n",
    "    lr = trial.suggest_float('learning_rate', 0.001, 0.003)\n",
    "    nHiddenLayers = trial.suggest_int('n_layers', 1, 6)\n",
    "    weightDecay = trial.suggest_float('weigth_decay', 0, 1e-4)\n",
    "    gamma = trial.suggest_float('gamma', 0.975, 1)\n",
    "    numNodes = trial.suggest_int('n_nodes', 32, 128, step=16)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = SimplifiedModel(nHiddenLayers, numNodes).to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weightDecay)\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma)\n",
    "\n",
    "    train(model, criterion, optimizer, scheduler, device, 40, trial)\n",
    "    result = test(model, test_loader, criterion, device)\n",
    "    accuracies = result[1]\n",
    "    trial.set_user_attr(\"recall\", result[2])\n",
    "\n",
    "    return accuracies ## , sum_recalls / num_of_cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if withOptuna:\n",
    "    name = \"final Model\"\n",
    "\n",
    "    if name in optuna.get_all_study_names(storage=\"sqlite:///db1.sqlite3\"):\n",
    "        study = optuna.load_study(study_name=name, storage=\"sqlite:///db1.sqlite3\")\n",
    "    else: \n",
    "        study = optuna.create_study(direction='maximize', storage=\"sqlite:///db1.sqlite3\", study_name=name, sampler=optuna.samplers.TPESampler(n_startup_trials=5))\n",
    "\n",
    "    study.optimize(objective, n_trials=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, 'entire_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loading:\n",
    "# model = torch.load('entire_model.pth')\n",
    "# model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
